---
title: "Fitted Models"
author: "Hunter Blackwell, Marc Flores, Jeremy Iyonawan"
date: "2023-11-06"
output: word_document
---

```{r setup}
# Load in wine dataset and examine the data
wine <- read.csv("winequality.csv")
summary(wine)
str(wine)
```


```{r}
# Divide data into training and validation sets
set.seed(1)
train.index <- sample(c(1:dim(wine)[1]), dim(wine)[1]*0.6)
valid.index <- setdiff(c(1:dim(wine)[1]), train.index)

train.df <- wine[train.index, ]
valid.df <- wine[-train.index, ]
```


```{r}
# Select variables to be used for training
lm <- lm(quality ~ ., data = wine)
options(scipen = 999)
summary(lm)

# Backward
lm.back <- step(lm, direction = "backward")
summary(lm.back)

# Forward
wine.lm.null <- lm(quality ~ 1, data = wine)
lm.forward <- step(wine.lm.null, scope = list(lower = wine.lm.null, upper = lm), direction = "forward")
summary(lm.forward)

# Both
lm.both <- step(lm, direction = "both")
summary(lm.both)

# Exhaustive search to further narrow down model
library(leaps)
exhaust <- regsubsets(quality ~ ., data = train.df, nbest = 1, nvmax = dim(train.df)[2], method = "exhaustive")
sum.exhaust <- summary(exhaust)
sum.exhaust$which
sum.exhaust$rsq
sum.exhaust$adjr2

# Use volatile.acidity, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, pH, sulphates, and alcohol.
```

```{r}
# Model 1 (Base Model)

# Fit the base model
wine.lm <- lm(quality ~ volatile.acidity + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + pH + sulphates + alcohol, data = train.df)
options(scipen = 999)
summary(wine.lm)

# Make predictions
library(forecast)
wine.lm.predict <- predict(wine.lm, valid.df)
some.residuals <- valid.df$quality - wine.lm.predict
pred.results <- data.frame("Predicted" = wine.lm.predict, "Actual" = valid.df$quality, "Residual" = some.residuals)

#pred.results

# Compute accuracy measures
acc <- accuracy(wine.lm.predict, valid.df$quality)
acc # RMSE of 0.64876

# 10 fold cross validation result
library(caret)
fold <- train(quality ~ volatile.acidity + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + pH + sulphates + alcohol, data = train.df, method = "lm", trControl = trainControl(method = "cv", number = 10))
fold # RMSE of 0.64788
# Use 10 fold cross validation result to make new predictions
fold.predict <- predict(fold, valid.df)
fold.residuals <- valid.df$quality - fold.predict
fold.results <- data.frame("Predicted" = fold.predict, "Actual" = valid.df$quality, "Residual" = fold.residuals)
cm.fold <- confusionMatrix(data = as.factor(round(fold.results$Predicted)), reference = as.factor(valid.df$quality))
cm.fold # 59.06% accuracy

# Percentage of accurate predictions
percent.accurate <- (((length(which(round(pred.results$Predicted, digits = 0) == pred.results$Actual))) / length(pred.results$Predicted))) * 100
percent.accurate # 59.06% accurate, same as 10 fold cross validation accuracy

# Confusion Matrix
cm.1 <- confusionMatrix(data = as.factor(round(pred.results$Predicted)), reference = as.factor(valid.df$quality))
cm.1 # Confusion matrix confirms 59.06% accuracy
```

```{r}
# Model 2 (Improved Model)

# Check for outliers to remove
summary(wine)
# Of the 7 variables used, Total sulfur dioxide and free sulfure dioxide have potential outliers
# Remove upper and lower 10% of both to make data more accurate
library(data.table)
wine.trim <- as.data.table(wine)
# Total sulfur dioxide
wine.trim <- wine.trim[total.sulfur.dioxide >= quantile(total.sulfur.dioxide, 0.1) & total.sulfur.dioxide <= quantile(total.sulfur.dioxide, 0.9)]
# Free sulfur dioxide
wine.trim <- wine.trim[free.sulfur.dioxide >= quantile(free.sulfur.dioxide, 0.1) & free.sulfur.dioxide <= quantile(free.sulfur.dioxide, 0.9)]
#Exam data to find less spread among total and free sulfur dioxide
summary(wine.trim)

# Resplit data
set.seed(4)
train.index1 <- sample(c(1:dim(wine.trim)[1]), dim(wine.trim)[1]*0.6)
valid.index1 <- setdiff(c(1:dim(wine.trim)[1]), train.index1)

train.df1 <- wine.trim[train.index1, ]
valid.df1 <- wine.trim[-train.index1, ]

# Fit the model
wine.lm1 <- lm(quality ~ volatile.acidity + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + pH + sulphates + alcohol, data = train.df1)
options(scipen = 999)
summary(wine.lm1)

# Make predictions
wine.lm.predict1 <- predict(wine.lm1, valid.df1)
some.residuals1 <- valid.df1$quality - wine.lm.predict1
pred.results1 <- data.frame("Predicted" = wine.lm.predict1, "Actual" = valid.df1$quality, "Residual" = some.residuals1)

#pred.results1

# Compute accuracy measures
acc1 <- accuracy(wine.lm.predict1, valid.df1$quality)
acc1 # .6004 RMSE compared to 0.64876 RMSE of base model

# 10 fold cross validation result
fold1 <- train(quality ~ volatile.acidity + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + pH + sulphates + alcohol, data = train.df1, method = "lm", trControl = trainControl(method = "cv", number = 10))
fold1 # 0.65302 RMSE compared to 0.64788 RMSE of base model
# Use 10 fold cross validation result to make new predictions
fold1.predict <- predict(fold1, valid.df)
fold1.residuals <- valid.df$quality - fold1.predict
fold1.results <- data.frame("Predicted" = fold1.predict, "Actual" = valid.df$quality, "Residual" = fold1.residuals)
cm.fold1 <- confusionMatrix(data = as.factor(round(fold1.results$Predicted)), reference = as.factor(valid.df$quality))
cm.fold1 # 58.12 accuracy for 10 fold cross validation, lower than the base model.

# Percentage of accurate predictions
percent.accurate1 <- (((length(which(round(pred.results1$Predicted, digits = 0) == pred.results1$Actual))) / length(pred.results1$Predicted))) * 100
percent.accurate1 # 64.35% accuracy

# Confusion Matrix
cm.2 <- confusionMatrix(data = as.factor(round(pred.results1$Predicted)), reference = as.factor(valid.df1$quality))
cm.2 # Confusion matrix confirms 64.35% accuracy, which is higher than the base model and higher than the 10 fold cross validation accuracy.
```
```{r}
#Make new splits
set.seed(5)
train.index5 <- sample(c(1:dim(wine)[1]), dim(wine)[1]*0.6)
valid.index5 <- setdiff(c(1:dim(wine)[1]), train.index)

train.df5 <- wine[train.index5, ]
valid.df5 <- wine[-train.index5, ]

#regression tree 
library(rpart)
rtree.fit = rpart(quality ~ volatile.acidity + chlorides + free.sulfur.dioxide
                  + total.sulfur.dioxide + pH + sulphates + alcohol, data = train.df5
                  , method = "anova"
                  , control = rpart.control(minsplit = 30, cp = .001))

#prints complexity parameter table 
printcp(rtree.fit)

# Produces 2 plots. The first plots the r-square (apparent and apparent - from cross-validation) versus the number of splits. The second plots the Relative Error(cross-validation) +/- 1-SE from cross-validation versus the number of splits.
rsq.rpart(rtree.fit)

# plots the cross-validation results across 
plotcp(rtree.fit)

# Detailed results including surrogate splits 
#summary(rtree.fit)

#ugly tree
library(text)
library(textplot)
library(rpart.plot)
plot(rtree.fit, uniform=TRUE, 
     main="Regression Tree for Quality fo Wine")
text(rtree.fit, use.n=TRUE, all=TRUE, cex=.8)

#better printed tree
library(rpart.plot)
prp(rtree.fit)
cor(predict(rtree.fit, newdata = valid.df5),valid.df5$quality)^2

#Tried to prune the tree for better accuracy
pruned.rtree.fit<- prune(rtree.fit, cp= rtree.fit$cptable[which.min(rtree.fit$cptable[,"xerror"]),"CP"])
prp(pruned.rtree.fit, main="Pruned Regression Tree for Quality of Wine")
#Doesn't occur
cor(predict(pruned.rtree.fit, newdata = valid.df5),valid.df5$quality)^2

#Tried again
pruned2.rtree.fit = prune(rtree.fit, cp =.01)
prp(pruned2.rtree.fit, main = "Pruned Regression Tree for Quality of Wine")
#Doesn't occur
cor(predict(pruned2.rtree.fit, newdata = valid.df5),valid.df5$quality)^2
```

